{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ece3e34-2364-4a4c-b79a-39c4f595106d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "os.chdir(\"../\") # resets notebook directory to repository root folder (DO ONLY ONCE!)\n",
    "import gzip\n",
    "import tqdm\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "# import pyarrow as pa\n",
    "\n",
    "def flatten(matrix):\n",
    "    return [item for row in matrix for item in row]\n",
    "\n",
    "def simpleId(text):\n",
    "    try:\n",
    "        y=text.split('/')[-1]\n",
    "    except:\n",
    "        y='NONE'\n",
    "    return y\n",
    "\n",
    "def flush_buffer(lines, output_dir):\n",
    "    df = pl.DataFrame(lines, orient = \"row\", schema = columns)\n",
    "\n",
    "    out_path = os.path.join(output_dir, f\"funders.csv\")\n",
    "    file_exists = os.path.isfile(out_path)\n",
    "    # # USING pandas\n",
    "    # df.write_csv(\n",
    "    #     out_path,\n",
    "    #     has_header=not file_exists,\n",
    "    #     separator=',',\n",
    "    #     append=file_exists\n",
    "    # )\n",
    "    # USING polars\n",
    "    csv_str = df.write_csv(separator=';', include_header=not file_exists)\n",
    "    with open(out_path, 'a', encoding='utf-8') as f:\n",
    "        f.write(csv_str)\n",
    "    lines = []\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3119ba4-9fe5-4417-a84a-93881262fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_subfolder = \"data/openalex-snapshot/data/funders/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11be39b-6a30-4091-9996-b23230f08b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 subfolders\n"
     ]
    }
   ],
   "source": [
    "listdir=[subfolder for subfolder in sorted(os.listdir(snapshot_subfolder)) if 'updated' in subfolder]\n",
    "print(f\"Found {len(listdir)} subfolders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bb17e5-0552-4e79-9cc8-73bae3220744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part_000.gz']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(snapshot_subfolder+listdir[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2441e2-c787-4356-bbff-f5b63127d1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 files\n"
     ]
    }
   ],
   "source": [
    "files=flatten([[snapshot_subfolder+listdir[a]+'/'+i for i in os.listdir(snapshot_subfolder+listdir[a]) if 'part' in i] for a in range(len(listdir))])\n",
    "print(f\"Found {len(files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c3e228-d1a9-4db0-94c9-028ab96d89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example file: data/openalex-snapshot/data/funders/updated_date=2024-02-07/part_000.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Example file:\", files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef891bd5-c9a5-4ac8-beed-b79517489ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:01<00:00, 74.98it/s] \n"
     ]
    }
   ],
   "source": [
    "destination_csv_folder = \"data/funders/\"\n",
    "os.makedirs(destination_csv_folder, exist_ok=True)\n",
    "\n",
    "# before doing any damage, check if there are files in the destination folder and stop if there are, \n",
    "# because if there are already csv, it will append and might cause many duplicates\n",
    "if os.listdir(destination_csv_folder):  # listdir returns [] if empty\n",
    "    existing = os.listdir(destination_csv_folder)\n",
    "    raise RuntimeError(\n",
    "        f\"Destination folder '{destination_csv_folder}' is not empty! \"\n",
    "        f\"Found {len(existing)} file(s), e.g., {existing[:3]}. \"\n",
    "        f\"Please clean it before running this script to avoid appending duplicates.\"\n",
    "    )\n",
    "\n",
    "columns=columns=['id', 'display_name','country_code','grants_count','works_count']\n",
    "lines=[]\n",
    "for gzfile in tqdm(files):\n",
    "    with gzip.open(gzfile, 'rt') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                ll=[simpleId(data['id']),data['display_name'].replace(';','.')]\n",
    "                country_code = data['country_code']\n",
    "                if country_code is None:\n",
    "                    country_code = ''\n",
    "                ll.append(country_code)\n",
    "\n",
    "                ll.append(data[\"grants_count\"])\n",
    "                ll.append(data[\"works_count\"])\n",
    "                    \n",
    "                lines.append(ll)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Errore nel parsing della riga: {e}\")\n",
    "            if len(lines) > 1000:\n",
    "                lines = flush_buffer(lines, destination_csv_folder)\n",
    "lines = flush_buffer(lines, destination_csv_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env_enrico-gt_rocky] *",
   "language": "python",
   "name": "conda-env-env_enrico-gt_rocky-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
